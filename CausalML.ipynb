{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import feature_engineering as fe\n",
    "import sklift.datasets.datasets as sdd\n",
    "from class_learners import SLearner, TLearner, CorrSTLearner\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from metric import extendedERUPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><h1><b>Causal Machine Learning with Uplift Model</b></h1></p>\n",
    "<p><h4><b>The objective:</b> find the intervention that maximises positive outcome  </h4> </p>\n",
    "<p><h4><b>The data:</b> Hillstrom dataset</h4></p>\n",
    "\n",
    "64,000 randomly chosen customers, who last purchased within 12 months, have been been subject to the following email intervention:\n",
    "<ul>\n",
    "    <li>1/3 were randomly chosen to receive an e-mail campaign featuring Men's merchandise.</li>\n",
    "    <li>1/3 were randomly chosen to receive an e-mail campaign featuring Women's merchandise.</li>\n",
    "    <li>1/3 were randomly chosen to not receive an e-mail campaign.</li>\n",
    "</ul>\n",
    "The the behaviour of the customers was tracked up to two weeks after the email campaign.\n",
    "\n",
    "<i>I will use uplift models to determine the best email intervention for each customer: which email option (Men's merch, Women's merch, no email) suits best for which individual customer in order to maximise the number of visits of the online store.</i>\n",
    "\n",
    "<h5><b>Columns with information of before the email intervention:</b></h5>\n",
    "<ul>\n",
    "    <li><b>Recency: </b>Months since last purchase.</li>\n",
    "    <li><b>History_Segment:</b> Categorization of dollars spent in the past year.</li>\n",
    "    <li><b>History:</b> Actual dollar value spent in the past year.</li>\n",
    "    <li><b>Mens:</b> 1/0 indicator, 1 = customer purchased Mens merchandise in the past year.</li>\n",
    "    <li><b>Womens:</b> 1/0 indicator, 1 = customer purchased Womens merchandise in the past year.</li>\n",
    "    <li><b>Zip_Code:</b> Classifies zip code as Urban, Suburban, or Rural.</li>\n",
    "    <li><b>Newbie:</b> 1/0 indicator, 1 = New customer in the past twelve months.</li>\n",
    "    <li><b>Channel:</b> Describes the channels the customer purchased from in the past year.</li>    \n",
    "</ul>\n",
    "<h5><b>Intervention column:</b></h5>\n",
    "<ul>\n",
    "<li><b>Segment:</b></li>\n",
    "<ul>\n",
    "    <li>Mens E-Mail</li>\n",
    "    <li>Womens E-Mail</li>\n",
    "    <li>No E-Mail</li>\n",
    "</ul>\n",
    "</ul>\n",
    "\n",
    "<h5><b>Columns tracking the activity of the customers up to two weeks after the email intervention:</b></h5>\n",
    "<ul>\n",
    "    <li><b>Visit:</b> 1/0 indicator, 1 = Customer visited website in the following two weeks.</li>\n",
    "    <li><b>Conversion: </b>1/0 indicator, 1 = Customer purchased merchandise in the following two weeks.</li>\n",
    "    <li><b>Spend:</b> Actual dollars spent in the following two weeks.</li>\n",
    "</ul>\n",
    "<br>\n",
    "<p><h4><b>Causal Machine Learning:</b></h4></b>\n",
    "<p>We would like to know how an individual customer will react when being subjected to a specific intervention. However, we can't perform multiple interventions on the same individual in order to see what would be the best option. The best approach is to use randomised controlled trial data (RCT): in these datasets, the interventions have been given randomly to a large enough number of individuals in order to deduce causal inference. </p>\n",
    "<p>For example, there are two possible interventions: send an email or send no email. My objective is that I would like customers to visit my store. In my database, I look at customer A and wonder whether I should send an email. The RCT data should be a large enough pool of people so that at least two people, who are very similar to my customer A, had been subject to either intervention \"email\" or intervention \"no email\". My model (meta-learner) should give me the probabilities of success of each intervention on customer A, or - if looking at the uplift - the difference of these probabilities. This should give me enough insight to take an informed decision.</p>\n",
    "<p>The hillstrom data set is a randomised controlled trial dataset: the interventions have been given randomly to a large enough number of customers in order to deduce causal inferences. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'treatment', 'DESCR', 'feature_names', 'target_name', 'treatment_name'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hillstrom = sdd.fetch_hillstrom(target_col='visit', data_home=None, dest_subdir=None, download_if_missing=True, return_X_y_t=False)\n",
    "hillstrom.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recency</th>\n",
       "      <th>history_segment</th>\n",
       "      <th>history</th>\n",
       "      <th>mens</th>\n",
       "      <th>womens</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>newbie</th>\n",
       "      <th>channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>2) $100 - $200</td>\n",
       "      <td>142.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Surburban</td>\n",
       "      <td>0</td>\n",
       "      <td>Phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>3) $200 - $350</td>\n",
       "      <td>329.08</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Rural</td>\n",
       "      <td>1</td>\n",
       "      <td>Web</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recency history_segment  history  mens  womens   zip_code  newbie channel\n",
       "0       10  2) $100 - $200   142.44     1       0  Surburban       0   Phone\n",
       "1        6  3) $200 - $350   329.08     1       1      Rural       1     Web"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hillstrom_features = hillstrom['data']\n",
    "hillstrom_features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Womens E-Mail\n",
       "1        No E-Mail\n",
       "Name: segment, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hillstrom_target = hillstrom['target']\n",
    "hillstrom_treatment = hillstrom['treatment']\n",
    "hillstrom_treatment.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><h3><b>Feature engineering</b></h3></p>\n",
    "Change the following columns to datatype `category`:\n",
    "<ul>\n",
    "    <li>mens</li>\n",
    "    <li>womens</li>\n",
    "    <li>newbi</li>\n",
    "</ul>\n",
    "<p>Change the following columns to datatype `category` and create dummies:\n",
    "<ul>\n",
    "    <li>zip_code</li>\n",
    "    <li>channel</li>\n",
    "</ul></p>\n",
    "<p>Mapping the values (\"no email\", \"Women's email\", and \"Men's email\") of the treatment to 0, 1, and 2.</p>\n",
    "<p>Dropping the column `history_segment`.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recency</th>\n",
       "      <th>history</th>\n",
       "      <th>mens</th>\n",
       "      <th>womens</th>\n",
       "      <th>newbie</th>\n",
       "      <th>zip_code_Rural</th>\n",
       "      <th>zip_code_Surburban</th>\n",
       "      <th>zip_code_Urban</th>\n",
       "      <th>channel_Multichannel</th>\n",
       "      <th>channel_Phone</th>\n",
       "      <th>channel_Web</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.603876</td>\n",
       "      <td>-0.194501</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.033679</td>\n",
       "      <td>0.169807</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    recency   history  mens  womens  newbie  zip_code_Rural  \\\n",
       "0  0.603876 -0.194501     1       0       0               0   \n",
       "1  0.033679  0.169807     1       1       1               1   \n",
       "\n",
       "   zip_code_Surburban  zip_code_Urban  channel_Multichannel  channel_Phone  \\\n",
       "0                   1               0                     0              1   \n",
       "1                   0               0                     0              0   \n",
       "\n",
       "   channel_Web  \n",
       "0            0  \n",
       "1            1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hillstrom_features = fe.feature_engineering(hillstrom_features)\n",
    "hillstrom_features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "Name: segment, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hillstrom_treatment = fe.treatment_category(hillstrom_treatment)\n",
    "hillstrom_treatment.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><h3><b>S-Learner, T-Learner, and correlated ST-Learner  </b></h3></p>\n",
    "Meta-learners are frameworks to estimate the Conditional Average Treatment Effect (CATE) or \"Uplift\" using any machine learning estimators. In this case, I will use Meta-learners to build a recommendation machine based on uplift models. I will use the S-, T-, and correlated T-learner as base models. As estimators I will use XGBoost, Random Forest, and Logistic Regression for each learner. Instead of computing the uplift of each email intervention, I will compare the probabilities of each intervention and opt for the treatment with the highest probability.<br>\n",
    "The following explanations assume binary treatment options.\n",
    "<p><h4><b>S-Learner:</b></h4></p>\n",
    "<p>Contrary to the T-learner, the S-learner uses only one machine learning model (single base).\n",
    "$$\n",
    "\\mu = E[Y|X=x, W=w]\n",
    "$$\n",
    "with $\\mu$ being average outcome, $Y$ the outcome, $X$ the covariate, and $W$ the treatment effect.</p>\n",
    "<p>The CATE is </p>\n",
    "$$\\tau(x) = \\hat{\\mu}(x,w = 1) - \\hat{\\mu}(x,w = 0).$$\n",
    "<p><h4><b>T-Learner:</b></h4></p>\n",
    "<p>The T-learner uses a model for each treatment option:\n",
    "$$\\mu_{0} = E[Y(0)|X=x],\\quad \\mu_{1} = E[Y(1)|X=x]$$.</p>\n",
    "<p>The CATE is $\\tilde{\\tau} = \\mu_{1}(x) - \\mu_{0}(x)$.</p>\n",
    "<p><h4><b>correlated ST-Learner:</b></h4></p>\n",
    "<p>The correlated ST-learner is a boosted mixture of both the S- and the T-learner. The train and test data will be prepared according to the T- and S-learner, respectively.There are four models to be considered: the base model and the three booster models. The base model is an xgboost on the whole train data. The three booster models are models for $$\\mu = E[Y(i)|X=x,W=i]$$ each boosted from the base model, where $i = 0,1$. The CATE is the same as for the S-learner. </p>\n",
    "<hr>\n",
    "<h5><b>S-Learner:</b></h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = SLearner(hillstrom_features, hillstrom_treatment, hillstrom_target)\n",
    "best_proba_logreg_S = s.get_proba(LogisticRegression,random_state = 42)\n",
    "best_proba_randfor_S = s.get_proba(RandomForestClassifier,max_depth=2,min_samples_leaf=2, random_state=42)\n",
    "best_proba_xgb_S = s.get_proba(xgb.XGBClassifier, seed=42, use_label_encoder=False, max_depth=1,eval_metric=\"logloss\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5><b>T-Learner:</b></h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = TLearner(hillstrom_features, hillstrom_treatment, hillstrom_target)\n",
    "best_proba_logreg_T = t.get_proba(LogisticRegression, 'segment', random_state = 42)\n",
    "best_proba_randfor_T = t.get_proba(RandomForestClassifier,'segment', max_depth=2,min_samples_leaf=2, random_state=42)\n",
    "best_proba_xgb_T = t.get_proba(xgb.XGBClassifier, 'segment', seed = 42, use_label_encoder=False, max_depth=1,eval_metric=\"logloss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5><b>Correlated ST-Learner:</b></h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = CorrSTLearner(hillstrom_features, hillstrom_treatment, hillstrom_target)\n",
    "ct.prepare_data()\n",
    "best_proba_xgb_cT = ct.get_proba(seed=42, use_label_encoder=False, max_depth=1,eval_metric=\"logloss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERUPT model: 2.0000, sum of y: 21270, number of rows: 10635\n",
      "ERUPT benchmark: 2.0000, sum of y: 21270, number of rows: 10635\n",
      "Difference of ERUPT(model) and ERUPT(benchmark): 0.0000\n",
      "ERUPT benchmark: 2.0000, sum of y: 21270, number of rows: 10635\n",
      "Difference of ERUPT(model) and ERUPT(benchmark_2): 0.0000\n"
     ]
    }
   ],
   "source": [
    "ee = extendedERUPT(best_proba_logreg_S,s.test_treatment)\n",
    "erupt_value_test, erupt_value_bench_2, erupt_bench_values = ee.get_ERUPT_with_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERUPT model: 1.6402, sum of y: 17491, number of rows: 10664\n",
      "ERUPT benchmark: 1.6405, sum of y: 17522, number of rows: 10681\n",
      "Difference of ERUPT(model) and ERUPT(benchmark): -0.0003\n",
      "ERUPT benchmark: 1.6412, sum of y: 17479, number of rows: 10650\n",
      "Difference of ERUPT(model) and ERUPT(benchmark_2): -0.0010\n"
     ]
    }
   ],
   "source": [
    "ee = extendedERUPT(best_proba_xgb_cT, ct.test_treatment)\n",
    "erupt_value_test, erupt_value_bench_2, erupt_bench_values = ee.get_ERUPT_with_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af3ce40c6df29b30509b69969a79933da8b03df3e30778ed537b7aec11dfb32e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
